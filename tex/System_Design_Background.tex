\section{System Background}
\subsection{Programmable Logic in the Middle(PLIM)}
    Here we detail the necessary background on interposing a module between a traditional multi-core processor and main memory.

    Commercially available SoCs integrate a traditional embedded multi-core processor system (PS) and a block of programmable logic (PL) with high-performance PS-PL communication interfaces. High-performance masters (HPM) and high-performance slaves (HPS) send and receive transactions to and from the PL, respectively. However, HPS's are not the only interface mediums for PL-PS communications. The chip has (limited number of) programmable interrupt lines present connected from the PL to the generic interrupt controller (GIC) inside the PS, whereas the GIC is a primary resource for managing interrupts sent to the processors. Like any other interrupt source in the system, a unique ID number identifies each of the PL-PS interrupts lines. Hence, by providing proper handlers associated with specific interrupt ID lines and unmasking them, PL can request a desired service routine from the PS. Nevertheless, as PS is buttressed by Arm Cortex-A53 Based Application Processing Unit (APU), the interrupt controller supports security extension to manage secure and non-secure interrupts grouped by  ARM TrustZone.


    The underlying mechanism is the ability to intercept memory transactions originated from the processors inside the PS, at the PL. Intercepted transactions are then forwarded from the PL again toward the memory controller inside the PS. The primary mechanism of PS-PL and PL-PS redirection of a transaction is called the Memory Loop-Back. Loop-Back is done through address bit manipulation of the transaction such that it falls in the range of the target HPM(HPS) for the PS-PL(PL-PS) interception. In this way, the main memory content is accessed, but through a programmable environment. It is possible to act on the characteristics of the traffic that now traverses the PL. For example, in the PL, it is possible to direct the transaction to arbitrary modules before, eventually, redirecting it back to PS and the memory controller, ultimately.

    This provides a unique capability of manipulating individual memory transactions. Hence, by sitting between CPUs and main memory, PLIM is exploited to perform memory scheduling. A configurable memory scheduler in the middle, namely, SchIM, is designed to implement several elected scheduling policies of Fixed Priority, TDMA, and Memguard. With
    SchIM, now we can enforce policy at the level of the transaction altogether by the hardware.
\subsection{Jailhouse, the partitioning Hypervisor}
Jailhouse is a well-known open-source partitioning hypervisor \footnote{The source code is available at \url{https://github.com/siemens/jailhouse.git}.} based on Linux,
 with a prominent levity due to focusing on software-based partitioning of only a handful of essential resources, i.e., on-chip resources like CPUs, memory regions, I/O devices, and skipping any virtual scheduling.

In jailhouses 
nomenclature, Virtual Machines (VMs) are referred to as inmate cells where Jailhouse already supports colored mappings. An inmate can be either a bare-metal application or any operating system like Linux, each programmed to see a contiguous Intermediate Physical Address (IPA) space. At the second stage, Jailhouse maps IPAs of different cells to Physical Addresses (PAs) with a configurable color specification. By doing so, Jailhouse supports the notion of temporal partitioning wherein, by assigning a collection of non-overlapping sets of processors to colored inmates, those cells cannot access a (physical) address beyond their own address space resulting in interference prevention.

Jailhouse gets enabled on top of a Linux, called root-cell, and uses a configuration file associated with it to split off parts of the system's resources and assign them to desired cells. Last but not least, Jailhouse is especially useful since one can circumvent the TrustZonce switches in any ARM-adapted OS (e.g., Linux), exploiting the hypervisor calls.

\subsubsection{PS-PL SoCs}
\subsubsection{Memory-Loopback}
\subsubsection{Cache Bleaching}
\subsubsection{Transaction-level Inspection}


\subsection{Cache and DRAM temporal partitioning}

\subsubsection{Partitioning}
        \subsubsection{Run-time Zero-Copy Recoloring support}

\subsection{Advanced eXtensible Interface (AXI)}
    \label{subsec:axi_transaction_scheme}
    The Advanced eXtensible Interface (or AXI for short) is a widely spread open specification bus protocol proposed by ARM \cite{ARM-AXI} and exploited by Xilinx to interface both the PL side and the PS side.\\
    The AXI protocol is based on the master-slave duality. Typically, the former is in charge of instantiating transactions directed to any of the slaves composing the system.
    On the other hand, the latter, does not emit any transaction but receive the requests emitted by a master and answer them.
    The masters and the slaves communicate between each other through five different channels named AW, W, B, AR and R as illustrated in figure \ref{fig:axi_transaction_scheme_figure}.
    A write transaction will start first by its address phase \circled{1}.
    That is, the transmission through the channel AW of meta-data regarding the transaction such as the destination address, the transaction ID, the amount of bursts and so on.
    Upon the completion of this phase, follows the data phase \circled{2} which, as its name suggests it, consists in the transmission of the payload itself through the W channel.
    Thereafter, comes the response phase \circled{3} performed on the B channel.
    This phase, the only one being initiated by the slave, is used to inform the master whether the transaction has been completed successfully.
    The transmission of a read transaction is carried out in a similar way.
    In fact, as for the writing, the address phase \circled{1'} is transmitted through the equivalent channel called AR and is directly followed by the data phase \circled{2'}.
    However, unlike the writing scheme, the data being fetched, the data phase is instantiated by the slave.
    The reading response phase is performed simultaneously and is thus merge within the R channel.\\
    The protocol is said to be asynchronous as transaction behaves similarly to packets each having a dedicated ID.
    Hence, multiple outstanding transactions can be emitted successively by a single master which can managed them in an out-of-order manner.

    \begin{figure}
        \centering
        \input{tikz/axi_transaction_scheme.tex}
        \caption{Caption}
        \label{fig:axi_transaction_scheme_figure}
    \end{figure}
